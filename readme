# ğŸŒ¡ï¸ Sensor Data Ingestion Pipeline

This project is a Python-based pipeline that ingests raw sensor data in CSV format, performs cleaning, transformation, validation, and stores it efficiently in Parquet format, optimized for analytical workloads.

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Raw CSV input files
â”‚   â””â”€â”€ processed/        # Partitioned, compressed Parquet output
â”œâ”€â”€ ingest.py             # Main entry point
â”œâ”€â”€ transform.py          # Data cleaning, calibration, transformation
â”œâ”€â”€ validate.py           # Data quality checks using DuckDB
â”œâ”€â”€ loader.py             # Optimized Parquet storage
â”œâ”€â”€ data_quality_report.csv
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/sensor-pipeline.git
cd sensor-pipeline
```

### 2. Set Up Virtual Environment

```bash
python -m venv env
source env/bin/activate   # On Windows: env\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

## â–¶ï¸ Running the Pipeline

Place raw sensor CSV files inside the `data/raw/` directory.

Then run:

```bash
python ingest.py
```

This will:

1. Clean and calibrate the sensor data.
2. Detect anomalies.
3. Validate data using DuckDB.
4. Store the processed data in partitioned Parquet format.
5. Generate `data_quality_report.csv`.

## ğŸ§  Logic Breakdown

### âœ… Calibration

Each sensor reading is calibrated as:

```
calibrated_value = raw_value * multiplier + offset
```

Configured in `transform.py`.

### âš ï¸ Anomaly Detection

Flag values that fall outside configured range.

### ğŸ§ª Validation with DuckDB

Checks:

- Correct types (float, timestamp)
- Hourly time coverage using `generate_series`
- Missing data
- Anomalies
- Time gaps

Output: `data_quality_report.csv`

## ğŸ§Š Storage

Parquet format, partitioned by:

```
data/processed/date=YYYY-MM-DD/sensor_id=SENSOR_ID/readings.parquet
```

Optimizations:

- Columnar format
- Partitioning
- Snappy compression

## ğŸ“ Example Output

```
data/
â”œâ”€â”€ raw/
â”‚   â””â”€â”€ sensor_readings.csv
â”œâ”€â”€ processed/
â”‚   â””â”€â”€ date=2025-06-05/
â”‚       â””â”€â”€ sensor_id=sensor_1/
â”‚           â””â”€â”€ readings.parquet
â”œâ”€â”€ data_quality_report.csv
```

## ğŸ’¬ Contact

+91 9717089280/ +91 7011318607

ğŸ“Œ Author: Kishor Kumar
ğŸ“… Date: July 2025